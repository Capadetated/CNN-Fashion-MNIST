# -*- coding: utf-8 -*-
"""Model Fashion MNIST Database Master.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jxp96DXeG_6q7TWUUl4l2YcGrZfWg5M0

**Assignment 4**
**CNN Analysis on Fashion MNIST Dataset:**
**Image Identification of Clothing Items**

Generated by Theodore Fitch

Department of Data Analytics, University of Maryland Global Campus

DATA 640: Predictive Modeling

Dr. Steven Knode: March 5th, Spring 2024

**Import libraries, import data, and explore data:**
"""

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

# Map for human readable class names (West, 2024)
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Load and preprocess the Fashion MNIST dataset
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# Fetch "Fashion MNIST" data (West, 2024)
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

# A good rule of thumb is to normalise input values - i.e. transform them to a
# scale of 0 to 1. Each element in this dataset is a pixel value of 0 to 255, so
# we'll normalise / rescale these values (West, 2024)
x_train = x_train / 255.0
x_test = x_test / 255.0

# Plot the first 25 images in the training dataset (West, 2024)
plt.figure(figsize=(15,15))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(x_train[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[y_train[i]])
plt.show()

# Lets view the first image and classname in the dataset
# Tip: Change "index" value to view different images (West, 2024)
index = 0
plt.figure(figsize=(20,16))
plt.imshow(x_train[index], cmap=plt.cm.binary)
plt.xlabel(class_names[y_train[index]])
plt.colorbar()
plt.grid(True)
plt.rc('grid', linestyle="-", color='fuchsia')

ax = plt.gca()
ax.set_xticks(np.arange(-.5, 28, 1))
ax.set_yticks(np.arange(-.5, 28, 1))
ax.set_xticklabels(np.arange(0, 29, 1))
ax.set_yticklabels(np.arange(0, 29, 1))
ax.xaxis.tick_top()

# Adds Pixel Values on top of image (West, 2024)
for i in range(28):
    for j in range(28):
        text = ax.text(j, i, round(x_train[index][i, j], 2),
                       ha="center", va="center", color="fuchsia")


plt.show()

"""**Model 1**: Baseline model (West, 2024)"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Assuming you have train_labels, test_labels, train_images, and test_images

# Build the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)

# Evaluate the model
predictions = model.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy: {accuracy * 100:.2f}%')
print(f'True Positive Rate: {tpr * 100:.2f}%')
print(f'Specificity: {specificity * 100:.2f}%')
print(f'Precision: {precision * 100:.2f}%')
print(f'F1 Score: {f1 * 100:.2f}%')

"""**Model 2**: Model 1, adjusted for:


*   Increased convolutional filters from 64 to 128 in the third layer
*   Increased neurons in first dense layer from 64 to 128
*   Added a dropout layer of rate 0.5
*   Increased epochs from 10 to 15




"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score


# Model2: Adjusted CNN model for increased accuracy
model2 = Sequential()
model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model2.add(MaxPooling2D((2, 2)))
model2.add(Conv2D(64, (3, 3), activation='relu'))
model2.add(MaxPooling2D((2, 2)))
model2.add(Conv2D(128, (3, 3), activation='relu'))  # Increased filters
model2.add(Flatten())
model2.add(Dense(128, activation='relu'))  # Increased neurons
model2.add(Dropout(0.5))  # Added dropout for regularization
model2.add(Dense(64, activation='relu'))
model2.add(Dense(10, activation='softmax'))

# Compile Model2
model2.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

# Train Model2
model2.fit(train_images, train_labels, epochs=15, batch_size=64, validation_split=0.2)

# Evaluate Model2
predictions = model2.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model2): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model2): {tpr * 100:.2f}%')
print(f'Specificity (Model2): {specificity * 100:.2f}%')
print(f'Precision (Model2): {precision * 100:.2f}%')
print(f'F1 Score (Model2): {f1 * 100:.2f}%')

"""**Model 3**: Model 2, adjusted for:

*   Epochs increased to 50


"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Assuming you have train_labels, test_labels, train_images, and test_images

# Model3: Adjusted CNN model for increased accuracy
model3 = Sequential()
model3.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model3.add(MaxPooling2D((2, 2)))
model3.add(Conv2D(64, (3, 3), activation='relu'))
model3.add(MaxPooling2D((2, 2)))
model3.add(Conv2D(128, (3, 3), activation='relu'))  # Increased filters
model3.add(Flatten())
model3.add(Dense(128, activation='relu'))  # Increased neurons
model3.add(Dropout(0.5))  # Added dropout for regularization
model3.add(Dense(64, activation='relu'))
model3.add(Dense(10, activation='softmax'))

# Compile Model3
model3.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

# Train Model3
model3.fit(train_images, train_labels, epochs=50, batch_size=64, validation_split=0.2)

# Evaluate Model3
predictions = model3.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model3): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model3): {tpr * 100:.2f}%')
print(f'Specificity (Model3): {specificity * 100:.2f}%')
print(f'Precision (Model3): {precision * 100:.2f}%')
print(f'F1 Score (Model3): {f1 * 100:.2f}%')

"""**Model 4**: Model 2, adjusted for:


*   Batch normalization layers added after each convolutional layer
*   Increased neurons of first dense layer from 128 to 256
*   Dropout rate fine tuned to 0.4 and 0.3 after the first and second dense layers respectively

"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Flatten, Dense, Dropout
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Assuming you have train_labels, test_labels, train_images, and test_images

# Model4: Further Adjusted CNN model for increased accuracy
model4 = Sequential()
model4.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model4.add(BatchNormalization())  # Added Batch Normalization
model4.add(AveragePooling2D((2, 2)))
model4.add(Conv2D(64, (3, 3), activation='relu'))
model4.add(BatchNormalization())  # Added Batch Normalization
model4.add(AveragePooling2D((2, 2)))
model4.add(Conv2D(128, (3, 3), activation='relu'))
model4.add(BatchNormalization())  # Added Batch Normalization
model4.add(Flatten())
model4.add(Dense(256, activation='relu'))  # Increased neurons
model4.add(Dropout(0.4))  # Adjusted dropout rate
model4.add(Dense(128, activation='relu'))
model4.add(Dropout(0.3))  # Adjusted dropout rate
model4.add(Dense(10, activation='softmax'))

# Compile Model4
model4.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

# Train Model4
model4.fit(train_images, train_labels, epochs=15, batch_size=64, validation_split=0.2)

# Evaluate Model4
predictions = model4.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model4): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model4): {tpr * 100:.2f}%')
print(f'Specificity (Model4): {specificity * 100:.2f}%')
print(f'Precision (Model4): {precision * 100:.2f}%')
print(f'F1 Score (Model4): {f1 * 100:.2f}%')

"""**Model 5**: Model 4, adjusted for:


*   Data was augmented using "imagedatagenerator" by adjusting images (using zoom, shifts, shear, or rotation) so that the model trains more robustly
*   Increased epochs to 30

"""

from tensorflow.keras import models, layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Assuming you have train_labels, test_labels, train_images, and test_images

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    horizontal_flip=True,
    vertical_flip=True
)

# Model5: Advanced CNN model with Data Augmentation
model5 = models.Sequential()
model5.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model5.add(layers.BatchNormalization())
model5.add(layers.MaxPooling2D((2, 2)))
model5.add(layers.Conv2D(64, (3, 3), activation='relu'))
model5.add(layers.BatchNormalization())
model5.add(layers.MaxPooling2D((2, 2)))
model5.add(layers.Conv2D(128, (3, 3), activation='relu'))
model5.add(layers.BatchNormalization())
model5.add(layers.Flatten())
model5.add(layers.Dense(256, activation='relu'))
model5.add(layers.Dropout(0.4))
model5.add(layers.Dense(128, activation='relu'))
model5.add(layers.Dropout(0.3))
model5.add(layers.Dense(10, activation='softmax'))

# Compile Model5
model5.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

# Data Augmentation and Training
history = model5.fit(
    datagen.flow(train_images, train_labels, batch_size=64),
    epochs=30,
    validation_data=(test_images, test_labels)
)

# Evaluate Model5
predictions = model5.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model5): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model5): {tpr * 100:.2f}%')
print(f'Specificity (Model5): {specificity * 100:.2f}%')
print(f'Precision (Model5): {precision * 100:.2f}%')
print(f'F1 Score (Model5): {f1 * 100:.2f}%')

"""**Model6**:

*   Decreased epochs to 10
*   Increased the number of filters in the convolutional layers
*   Increased the number of neurons in the dense layers
*   Used a leaning rate scheduler


"""

from tensorflow.keras import models, layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Assuming you have train_labels, test_labels, train_images, and test_images

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    horizontal_flip=True,
    vertical_flip=True
)

# Learning Rate Scheduler
def lr_scheduler(epoch):
    return 1e-3 * 0.9 ** epoch

lr_callback = LearningRateScheduler(lr_scheduler)

# Model6: Improved CNN model with Data Augmentation, Batch Normalization, and Learning Rate Scheduler
model6 = models.Sequential()
model6.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model6.add(layers.BatchNormalization())
model6.add(layers.MaxPooling2D((2, 2)))
model6.add(layers.Conv2D(128, (3, 3), activation='relu'))
model6.add(layers.BatchNormalization())
model6.add(layers.MaxPooling2D((2, 2)))
model6.add(layers.Conv2D(256, (3, 3), activation='relu'))
model6.add(layers.BatchNormalization())
model6.add(layers.Flatten())
model6.add(layers.Dense(512, activation='relu'))
model6.add(layers.Dropout(0.5))
model6.add(layers.Dense(256, activation='relu'))
model6.add(layers.Dropout(0.3))
model6.add(layers.Dense(10, activation='softmax'))

# Compile Model6
model6.compile(optimizer=Adam(learning_rate=1e-3),
               loss='categorical_crossentropy',
               metrics=['accuracy'])

# Data Augmentation and Training
history = model6.fit(
    datagen.flow(train_images, train_labels, batch_size=64),
    epochs=10,
    validation_data=(test_images, test_labels),
    callbacks=[lr_callback]
)

# Evaluate Model6
predictions = model6.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model6): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model6): {tpr * 100:.2f}%')
print(f'Specificity (Model6): {specificity * 100:.2f}%')
print(f'Precision (Model6): {precision * 100:.2f}%')
print(f'F1 Score (Model6): {f1 * 100:.2f}%')

"""**Model 7**: Model 2 with increased dense layer neurons, and increased filters"""

from tensorflow.keras import models, layers
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

# Assuming you have train_labels, test_labels, train_images, and test_images

# Model7: Adjusted CNN model from Model 2, increased batch size and dense layer neurons
model7 = models.Sequential()
model7.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model7.add(layers.MaxPooling2D((2, 2)))
model7.add(layers.Conv2D(128, (3, 3), activation='relu'))
model7.add(layers.MaxPooling2D((2, 2)))
model7.add(layers.Conv2D(256, (3, 3), activation='relu'))  # Increased filters
model7.add(layers.Flatten())
model7.add(layers.Dense(256, activation='relu'))  # Increased neurons
model7.add(layers.Dropout(0.2))  # Added dropout for regularization
model7.add(layers.Dense(128, activation='relu'))
model7.add(layers.Dense(10, activation='softmax'))

# Compile Model7
model7.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

# Train Model7
model7.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)

# Evaluate Model7
predictions = model7.predict(test_images)
predicted_labels = [np.argmax(prediction) for prediction in predictions]
true_labels = [np.argmax(label) for label in test_labels]

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calculate metrics
accuracy = accuracy_score(true_labels, predicted_labels)
tpr = recall_score(true_labels, predicted_labels, average='macro')  # True Positive Rate
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Specificity
precision = precision_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model7): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model7): {tpr * 100:.2f}%')
print(f'Specificity (Model7): {specificity * 100:.2f}%')
print(f'Precision (Model7): {precision * 100:.2f}%')
print(f'F1 Score (Model7): {f1 * 100:.2f}%')

"""**Final Model**: Model 8, based upon the TensorFlow (2024)"""

import tensorflow as tf
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score
from sklearn.model_selection import train_test_split

# Assuming you have train_labels, test_labels, train_images, and test_images

fashion_mnist = tf.keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

train_images = train_images / 255.0
test_images = test_images / 255.0

# Split the training data into training and validation sets
train_images, val_images, train_labels, val_labels = train_test_split(
    train_images, train_labels, test_size=0.2, random_state=42)

# Model8: Modified TensorFlow (2024) model with additional metrics and validation split
model8 = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(10)
])

model8.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

# Train Model8 with validation split
model8.fit(train_images, train_labels, epochs=15, validation_data=(val_images, val_labels))

# Evaluate Model8
predictions = model8.predict(test_images)
predicted_labels = [tf.argmax(prediction).numpy() for prediction in predictions]

# Calculate metrics
conf_matrix = confusion_matrix(test_labels, predicted_labels)
accuracy = accuracy_score(test_labels, predicted_labels)
tpr = recall_score(test_labels, predicted_labels, average='macro')
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])
precision = precision_score(test_labels, predicted_labels, average='macro')
f1 = f1_score(test_labels, predicted_labels, average='macro')

# Print metrics
print(f'Test Accuracy (Model8): {accuracy * 100:.2f}%')
print(f'True Positive Rate (Model8): {tpr * 100:.2f}%')
print(f'Specificity (Model8): {specificity * 100:.2f}%')
print(f'Precision (Model8): {precision * 100:.2f}%')
print(f'F1 Score (Model8): {f1 * 100:.2f}%')

"""**Print plot for first entry, and first 25 entries of model8**"""

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np
# Prepare predictions
temperature = 0.5
probability_model = tf.keras.Sequential([model8,
                                         tf.keras.layers.Softmax()])
predictions = probability_model.predict(test_images)


# Prepare Plots
def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

# Plot of first image only
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()

# Plot the first X test images, their predicted labels, and the true labels.
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 5
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()

"""**Print plot for first 25 incorrectly categorized entries from test dataset of model8**"""

# Prepare table
num_rows = 5
num_cols = 5
num_images = num_rows * num_cols
incorrect_indices = []

# Identify indices of incorrect predictions
for i in range(len(predictions)):
    if np.argmax(predictions[i]) != test_labels[i]:
        incorrect_indices.append(i)

# Plot the first 25 incorrect predictions
plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))
for i in range(num_images):
    idx = incorrect_indices[i]
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)
    plot_image(idx, predictions[idx], test_labels, test_images)
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)
    plot_value_array(idx, predictions[idx], test_labels)
plt.tight_layout()
plt.show()

"""**Confusion Matrix of Model 8**"""

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Assuming 'predictions' contains the predicted class labels (use np.argmax if needed)
predicted_labels = np.argmax(predictions, axis=1)

# Assuming 'test_labels' contains the true class labels
true_labels = test_labels

# Create the confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=np.arange(10))

# Print the confusion matrix with labels
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# You can also print a classification report for more detailed metrics
class_report = classification_report(true_labels, predicted_labels, target_names=class_names)
print("\nClassification Report:")
print(class_report)

"""**Confusion Matrix of Model 7**"""

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Prepare predictions
temperature = 0.5
probability_model = tf.keras.Sequential([model8,
                                         tf.keras.layers.Softmax()])
predictions = probability_model.predict(test_images)



# Assuming 'predictions' contains the predicted class labels (use np.argmax if needed)
predicted_labels = np.argmax(predictions, axis=1)

# Assuming 'test_labels' contains the true class labels
true_labels = test_labels

# Create the confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=np.arange(10))

# Print the confusion matrix with labels
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# You can also print a classification report for more detailed metrics
class_report = classification_report(true_labels, predicted_labels, target_names=class_names)
print("\nClassification Report:")
print(class_report)